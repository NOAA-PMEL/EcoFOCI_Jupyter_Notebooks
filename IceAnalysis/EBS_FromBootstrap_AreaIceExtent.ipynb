{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In house Calculations of Eastern Bering Sea Ice Extent in the manner of the SeaIce V3 product below.\n",
    "\n",
    "### Define boundaries and cycle through all Bootstrap/NRT data\n",
    "\n",
    "BS - 178E to Alaska (for EBS), 65.666N - all available points south.\n",
    "\n",
    "We want to compare to the Daily Bering Sea ice extent during the past fourty years (data from the NSIDC Regional Sea Ice Index) which does a more comprehensive job of masking out the basin then the simple box, but we are only interested in the ice over the EBS shelf.  A 5day trailing average is applied to the regional extent product.\n",
    "\n",
    "### SeaIce Extent V3 - Daily Updated\n",
    "\n",
    "__pyversion__==3.7   \n",
    "__author__==S.Bell\n",
    "\n",
    "__general info__ https://nsidc.org/data/g02135   \n",
    "__datasource__ ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/seaice_analysis/N_Sea_Ice_Index_Regional_Daily_Data_G02135_v3.0.xlsx\n",
    "\n",
    "See https://blogs.helmholtz.de/polarpredictionmatters/2018/07/polar-forecasts-against-impacts-of-declining-bering-sea-ice-on-alaska-coastal-communities-part-1/ for reference.\n",
    "\n",
    "Sources and Citations (see data)\n",
    "- Daily Bering Sea ice extent during the past fourty years (data from the NSIDC Regional Sea Ice Index)\n",
    "\n",
    "- Fetterer, F., K. Knowles, W. Meier, M. Savoie, and A. K. Windnagel. 2017, updated daily. Sea Ice Index, Version 3. [Indicate subset used]. Boulder, Colorado USA. NSIDC: National Snow and Ice Data Center. doi: https://doi.org/10.7265/N5K072F8. [Date Accessed]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import YearLocator, WeekdayLocator, MonthLocator, DayLocator, HourLocator, DateFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### specify primary bulk figure parameters\n",
    "fontsize = 20\n",
    "labelsize = 16\n",
    "#plotstyle = 'seaborn'\n",
    "plt.style.use('seaborn-ticks')\n",
    "mpl.rcParams['svg.fonttype'] = 'none'\n",
    "mpl.rcParams['ps.fonttype'] = 42 #truetype/type2 fonts instead of type3\n",
    "mpl.rcParams['pdf.fonttype'] = 42 #truetype/type2 fonts instead of type3\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['axes.edgecolor'] = 'black'\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.labelcolor'] = 'black'\n",
    "mpl.rcParams['grid.linestyle'] = '--'\n",
    "mpl.rcParams['grid.linestyle'] = '--'\n",
    "mpl.rcParams['xtick.major.size'] = 4\n",
    "mpl.rcParams['xtick.minor.size'] = 1\n",
    "mpl.rcParams['xtick.major.width'] = 2\n",
    "mpl.rcParams['xtick.minor.width'] = 1\n",
    "mpl.rcParams['ytick.major.size'] = 4\n",
    "mpl.rcParams['ytick.minor.size'] = 1\n",
    "mpl.rcParams['ytick.major.width'] = 2\n",
    "mpl.rcParams['ytick.minor.width'] = 1\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.color'] = 'black'\n",
    "mpl.rcParams['xtick.color'] = 'black'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = 'ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/seaice_analysis/N_Sea_Ice_Index_Regional_Daily_Data_G02135_v3.0.xlsx'\n",
    "page = 'Bering-Extent-km^2' #Bering-Area-km^2\n",
    "#fid = '/Users/bell/in_and_outbox/Ongoing_Analysis/SeaIce_Analysis/BeringSea_IceExtent/Sea_Ice_Index_Regional_Daily_Data_G02135_v3.0 EBS edit.xlsx'\n",
    "#page = 'EBering-Extent-km^2' #Bering-Area-km^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = pd.read_excel(fid,sheet_name=page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-15b3594a2d78>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfe[2021][dfe[2021].index > int(datetime.datetime.strftime(datetime.datetime.now(),'%j'))] = np.nan\n"
     ]
    }
   ],
   "source": [
    "dfe = dfe.interpolate()\n",
    "dfe['doy_y2'] = dfe.index+365\n",
    "\n",
    "#make missing days after present day\n",
    "dfe[2021][dfe[2021].index > int(datetime.datetime.strftime(datetime.datetime.now(),'%j'))] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 2' '1978d' '1979d' '1980d' '1981d' '1982d' '1983d' '1984d'\\n '1985d' '1986d' '1987d' '1988d' '1989d' '1990d' '1991d' '1992d' '1993d'\\n '1994d' '1995d' '1996d' '1997d' '1998d' '1999d' '2000d' '2001d' '2002d'\\n '2003d' '2004d' '2005d' '2006d' '2007d' '2008d' '2009d' '2010d' '2011d'\\n '2012d' '2013d' '2014d' '2015d' '2016d' '2017d' '2018d' '2019d' '2020d'\\n '5dayAve->'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-61712e40245f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;34m'2015d'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m'2016d'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m'2017d'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m'2018d'\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m'2019d'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             '2020d',  '5dayAve->','doy_y2']\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdfmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'avg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m59\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#make missing days select day\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/altair/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4306\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m         \"\"\"\n\u001b[0;32m-> 4308\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   4309\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/altair/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/altair/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4188\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/altair/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5590\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5591\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 2' '1978d' '1979d' '1980d' '1981d' '1982d' '1983d' '1984d'\\n '1985d' '1986d' '1987d' '1988d' '1989d' '1990d' '1991d' '1992d' '1993d'\\n '1994d' '1995d' '1996d' '1997d' '1998d' '1999d' '2000d' '2001d' '2002d'\\n '2003d' '2004d' '2005d' '2006d' '2007d' '2008d' '2009d' '2010d' '2011d'\\n '2012d' '2013d' '2014d' '2015d' '2016d' '2017d' '2018d' '2019d' '2020d'\\n '5dayAve->'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dfmean = dfe.copy()\n",
    "dfmean.drop(columns=[2018,2017,2016,2015],inplace=True)\n",
    "dfmean['avg'] = dfmean.drop(59,axis=0).drop(['month','day'], axis=1).mean(axis=1)\n",
    "#previous line has lots of columns that don't need to be part of the mean\n",
    "## unnamed (second doy) brings value down alot, but it also had the daily averages in it\n",
    "# so that should have brought it back up\n",
    "\n",
    "drop_cols = ['month',        'day', 'Unnamed: 2',      '1978d',      '1979d',\n",
    "            '1980d',      '1981d',      '1982d',      '1983d',      '1984d',\n",
    "            '1985d',      '1986d',      '1987d',      '1988d',      '1989d',\n",
    "            '1990d',      '1991d',      '1992d',      '1993d',      '1994d',\n",
    "            '1995d',      '1996d',      '1997d',      '1998d',      '1999d',\n",
    "            '2000d',      '2001d',      '2002d',      '2003d',      '2004d',\n",
    "            '2005d',      '2006d',      '2007d',      '2008d',      '2009d',\n",
    "            '2010d',      '2011d',      '2012d',      '2013d',      '2014d',\n",
    "            '2015d',      '2016d',      '2017d',      '2018d',      '2019d',\n",
    "            '2020d',  '5dayAve->','doy_y2']\n",
    "dfmean['avg'] = dfmean.drop(59,axis=0).drop(drop_cols, axis=1).mean(axis=1)\n",
    "\n",
    "#make missing days select day\n",
    "#dfe[2020][dfe[2020].index > int(datetime.datetime.strftime(datetime.datetime(2020,5,17),'%j'))] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start at Sep 1 (244)\n",
    "# Area Extent in x10^6 km^2\n",
    "\n",
    "fig = plt.figure(1,figsize=(9,2.125))\n",
    "ax1 = plt.subplot2grid((1, 1), (0, 0), colspan=1, rowspan=1)\n",
    "for yy in range(1978,2018,1):\n",
    "    plt.plot(dfe.index,dfe[yy]/1e6,c='gray',linewidth=.5,label='')\n",
    "    plt.plot(dfe['doy_y2'],dfe[yy]/1e6,c='gray',linewidth=.5,label='')\n",
    "    \n",
    "#Fall\n",
    "l1 = ax1.plot(dfmean.index,dfmean['avg']/1e6,'k',linewidth=2,label='1979-2014 mean')\n",
    "l2 = ax1.plot(dfe.index,dfe[1988]/1e6,'g',linewidth=2.5,label='1988/89')\n",
    "l3 = ax1.plot(dfe.index,dfe[2002]/1e6,'c-',linewidth=2.5,label='2002/03')\n",
    "l4 = ax1.plot(dfe.index,dfe[2011]/1e6,'b-',linewidth=2.5,label='2011/12')\n",
    "l5 = ax1.plot(dfe.index,dfe[2016]/1e6,'darkorange',linewidth=2.5,label='2016/17')\n",
    "l6 = ax1.plot(dfe.index,dfe[2017]/1e6,'r--',linewidth=2.5,label='2017/18')\n",
    "#l7 = ax1.plot(dfe.index,dfe[2018]/1e6,'y-',linewidth=2.5,label='2018/19')\n",
    "#Spring\n",
    "plt.plot(dfmean['doy_y2'],dfmean['avg']/1e6,'k',linewidth=2,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[1989]/1e6,'g',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2003]/1e6,'c-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2012]/1e6,'b-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2017]/1e6,'darkorange',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2018]/1e6,'r--',linewidth=2.5,label='')\n",
    "#plt.plot(dfe['doy_y2'],dfe[2019]/1e6,'y-',linewidth=2.5,label='')\n",
    "\n",
    "plt.legend()\n",
    "plt.xticks((0,31,61,92,122,153,183,214,245,275,306,336,\n",
    "               0+365,31+365,61+365,92+365,122+365,153+365,\n",
    "               183+365,214+365,245+365,275+365,306+365,336+365),)\n",
    "ax1.set_xlim([244,244+365])\n",
    "#plt.yticks(np.arange(0,1.2,.4))\n",
    "ax1.tick_params(axis='y',which='both',bottom='on')\n",
    "\n",
    "ax1.yaxis.set_minor_locator(ticker.MultipleLocator(2.5))\n",
    "ax1.xaxis.set_major_locator(DayLocator(bymonthday=1))\n",
    "ax1.xaxis.set_minor_locator(DayLocator(bymonthday=15))\n",
    "ax1.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax1.xaxis.set_minor_formatter(DateFormatter('%b'))\n",
    "ax1.xaxis.set_major_formatter(DateFormatter(''))\n",
    "ax1.xaxis.set_tick_params(which='major', pad=15)\n",
    "ax1.xaxis.set_tick_params(which='minor', pad=5)\n",
    "\n",
    "plt.ylabel('Sea Ice Extent (10$^{6}$ km$^{2}$)')\n",
    "fig.savefig('images/EBS_fig1.png',dpi=300)\n",
    "fig.savefig('images/EBS_fig1.svg',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start at Sep 1 (244)\n",
    "# Area Extent in x10^6 km^2\n",
    "\n",
    "fig = plt.figure(1,figsize=(9,2.125))\n",
    "ax1 = plt.subplot2grid((1, 1), (0, 0), colspan=1, rowspan=1)\n",
    "for yy in range(1978,2018,1):\n",
    "    plt.plot(dfe.index,dfe[yy]/1e6,c='gray',linewidth=.5,label='')\n",
    "    plt.plot(dfe['doy_y2'],dfe[yy]/1e6,c='gray',linewidth=.5,label='')\n",
    "    \n",
    "#Fall\n",
    "l1 = ax1.plot(dfmean.index,dfmean['avg']/1e6,'k',linewidth=2,label='1979-2014 mean')\n",
    "l2 = ax1.plot(dfe.index,dfe[1988]/1e6,'g',linewidth=2.5,label='1988/89')\n",
    "l4 = ax1.plot(dfe.index,dfe[2002]/1e6,'c-',linewidth=2.5,label='2002/03')\n",
    "l5 = ax1.plot(dfe.index,dfe[2011]/1e6,'b-',linewidth=2.5,label='2011/12')\n",
    "l6 = ax1.plot(dfe.index,dfe[2016]/1e6,'orange',linewidth=2.5,label='2016/17')\n",
    "l7 = ax1.plot(dfe.index,dfe[2017]/1e6,'r-',linewidth=2.5,label='2017/18')\n",
    "l8 = ax1.plot(dfe.index,dfe[2018]/1e6,'r--',linewidth=2.,label='2018/19')\n",
    "l9 = ax1.plot(dfe.index,dfe[2019]/1e6,'m-',linewidth=2.5,label='2019/20')\n",
    "l9 = ax1.plot(dfe.index,dfe[2020]/1e6,'m--',linewidth=2.5,label='2020/21')\n",
    "#Spring\n",
    "plt.plot(dfmean['doy_y2'],dfmean['avg']/1e6,'k',linewidth=2,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[1989]/1e6,'g',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2003]/1e6,'c-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2012]/1e6,'b-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2017]/1e6,'orange',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2018]/1e6,'r-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2019]/1e6,'r--',linewidth=2.,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2020]/1e6,'m-',linewidth=2.,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2021]/1e6,'m--',linewidth=2.5,label='')\n",
    "\n",
    "plt.legend(loc='right')\n",
    "plt.xticks((0,31,61,92,122,153,183,214,245,275,306,336,\n",
    "               0+365,31+365,61+365,92+365,122+365,153+365,\n",
    "               183+365,214+365,245+365,275+365,306+365,336+365),)\n",
    "ax1.set_xlim([244,244+365])\n",
    "#plt.yticks(np.arange(0,1.2,.4))\n",
    "ax1.tick_params(axis='y',which='both',bottom='on')\n",
    "\n",
    "ax1.yaxis.set_minor_locator(ticker.MultipleLocator(2.5))\n",
    "ax1.xaxis.set_major_locator(DayLocator(bymonthday=1))\n",
    "ax1.xaxis.set_minor_locator(DayLocator(bymonthday=15))\n",
    "ax1.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax1.xaxis.set_minor_formatter(DateFormatter('%b'))\n",
    "ax1.xaxis.set_major_formatter(DateFormatter(''))\n",
    "ax1.xaxis.set_tick_params(which='major', pad=15)\n",
    "ax1.xaxis.set_tick_params(which='minor', pad=5)\n",
    "    \n",
    "plt.ylabel('Sea Ice Extent (10$^{6}$ km$^{2}$)')\n",
    "fig.savefig('images/EBS_fig2.png',dpi=300)\n",
    "fig.savefig('images/EBS_fig2.svg',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(1,figsize=(10,4.5))\n",
    "ax1 = plt.subplot2grid((1, 1), (0, 0), colspan=1, rowspan=1)\n",
    "for yy in range(1978,2018,1):\n",
    "    plt.plot(dfe.index,dfe[yy]/1e6,c='gray',linewidth=.25,label='')\n",
    "    plt.plot(dfe['doy_y2'],dfe[yy]/1e6,c='gray',linewidth=.25,label='')\n",
    "    \n",
    "#Fall\n",
    "l1 = ax1.plot(dfmean.index,dfmean['avg']/1e6,'k',linewidth=2,label='1979-2014 mean')\n",
    "l5 = ax1.plot(dfe.index,dfe[2011]/1e6,'b-',linewidth=2.5,label='2011/12')\n",
    "l6 = ax1.plot(dfe.index,dfe[2016]/1e6,'orange',linewidth=2.5,label='2016/17')\n",
    "l7 = ax1.plot(dfe.index,dfe[2017]/1e6,'r-',linewidth=2.5,label='2017/18')\n",
    "l8 = ax1.plot(dfe.index,dfe[2018]/1e6,'maroon',linestyle='--',linewidth=2.5,label='2018/19')\n",
    "l8 = ax1.plot(dfe.index,dfe[2019]/1e6,'g-',linewidth=2.5,label='2019/20')\n",
    "#Spring\n",
    "plt.plot(dfmean['doy_y2'],dfmean['avg']/1e6,'k',linewidth=2,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2012]/1e6,'b-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2017]/1e6,'orange',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2018]/1e6,'r-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2019]/1e6,'maroon',linestyle='--',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2020]/1e6,'g-',linewidth=2.5,label='')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xticks((0,31,61,92,122,153,183,214,245,275,306,336,\n",
    "               0+365,31+365,61+365,92+365,122+365,153+365,\n",
    "               183+365,214+365,245+365,275+365,306+365,336+365),)\n",
    "ax1.set_xlim([244,244+365])\n",
    "#plt.yticks(np.arange(0,1.2,.4))\n",
    "ax1.tick_params(axis='y',which='both',bottom='on')\n",
    "\n",
    "ax1.yaxis.set_minor_locator(ticker.MultipleLocator(2.5))\n",
    "ax1.xaxis.set_major_locator(DayLocator(bymonthday=1))\n",
    "ax1.xaxis.set_minor_locator(DayLocator(bymonthday=15))\n",
    "ax1.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax1.xaxis.set_minor_formatter(DateFormatter('%b'))\n",
    "ax1.xaxis.set_major_formatter(DateFormatter(''))\n",
    "ax1.xaxis.set_tick_params(which='major', pad=15)\n",
    "ax1.xaxis.set_tick_params(which='minor', pad=5)\n",
    "    \n",
    "plt.ylabel('Sea Ice Extent (10$^{6}$ km$^{2}$)')\n",
    "fig.savefig('images/EBS_fig2.png',dpi=300)\n",
    "fig.savefig('images/EBS_fig2.svg',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate events in Northerly Winds that lead to anomolous Ice (Stabeno and Bell 2019, in press)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2009+\n",
    "\n",
    "# start at Sep 1 (244)\n",
    "# Area Extent in x10^6 km^2\n",
    "\n",
    "fig = plt.figure(1,figsize=(9,2.125))\n",
    "ax1 = plt.subplot2grid((1, 1), (0, 0), colspan=1, rowspan=1)\n",
    "for yy in range(2009,2018,1):\n",
    "    plt.plot(dfe.index,dfe[yy]/1e6,c='gray',linewidth=.5,label='')\n",
    "    plt.plot(dfe['doy_y2'],dfe[yy]/1e6,c='gray',linewidth=.5,label='')\n",
    "    \n",
    "#Fall\n",
    "l1 = ax1.plot(dfmean.index,dfmean['avg']/1e6,'k',linewidth=2,label='1979-2014 mean')\n",
    "l5 = ax1.plot(dfe.index,dfe[2011]/1e6,'b-',linewidth=2.5,label='2011/12')\n",
    "l6 = ax1.plot(dfe.index,dfe[2016]/1e6,'orange',linewidth=2.5,label='2016/17')\n",
    "l7 = ax1.plot(dfe.index,dfe[2017]/1e6,'r-',linewidth=2.5,label='2017/18')\n",
    "l8 = ax1.plot(dfe.index,dfe[2018]/1e6,'r--',linewidth=2.,label='2018/19')\n",
    "l9 = ax1.plot(dfe.index,dfe[2019]/1e6,'m-',linewidth=2.5,label='2019/20')\n",
    "#Spring\n",
    "plt.plot(dfmean['doy_y2'],dfmean['avg']/1e6,'k',linewidth=2,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2012]/1e6,'b-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2017]/1e6,'orange',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2018]/1e6,'r-',linewidth=2.5,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2019]/1e6,'r--',linewidth=2.,label='')\n",
    "plt.plot(dfe['doy_y2'],dfe[2020]/1e6,'m-',linewidth=2.5,label='')\n",
    "\n",
    "plt.legend(loc='right')\n",
    "plt.xticks((0,31,61,92,122,153,183,214,245,275,306,336,\n",
    "               0+365,31+365,61+365,92+365,122+365,153+365,\n",
    "               183+365,214+365,245+365,275+365,306+365,336+365),)\n",
    "ax1.set_xlim([244,244+365])\n",
    "#plt.yticks(np.arange(0,1.2,.4))\n",
    "ax1.tick_params(axis='y',which='both',bottom='on')\n",
    "\n",
    "ax1.yaxis.set_minor_locator(ticker.MultipleLocator(2.5))\n",
    "ax1.xaxis.set_major_locator(DayLocator(bymonthday=1))\n",
    "ax1.xaxis.set_minor_locator(DayLocator(bymonthday=15))\n",
    "ax1.xaxis.set_major_formatter(ticker.NullFormatter())\n",
    "ax1.xaxis.set_minor_formatter(DateFormatter('%b'))\n",
    "ax1.xaxis.set_major_formatter(DateFormatter(''))\n",
    "ax1.xaxis.set_tick_params(which='major', pad=15)\n",
    "ax1.xaxis.set_tick_params(which='minor', pad=5)\n",
    "    \n",
    "plt.ylabel('Sea Ice Extent (10$^{6}$ km$^{2}$)')\n",
    "fig.savefig('images/EBS_fig3.png',dpi=300)\n",
    "fig.savefig('images/EBS_fig3.svg',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### March 15th amount vs annual max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(9,2.125))\n",
    "ax1 = plt.subplot2grid((1, 1), (0, 0), colspan=1, rowspan=1)\n",
    "plt.plot(dfe.iloc[74][47:-1]/1e6,label='March 15')\n",
    "plt.plot(dfe.max()[47:-1]/1e6,label='Calendar Year Max')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Sea Ice Extent (10$^{6}$ km$^{2}$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL BS (resets rest of routine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All BS\n",
    "fid = 'ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/seaice_analysis/N_Sea_Ice_Index_Regional_Daily_Data_G02135_v3.0.xlsx'\n",
    "page = 'Bering-Extent-km^2' #Bering-Area-km^2\n",
    "\n",
    "dfe = pd.read_excel(fid,sheet_name=page)\n",
    "\n",
    "dfe = dfe.interpolate()\n",
    "dfe['doy_y2'] = dfe.index+365\n",
    "\n",
    "dfmean = dfe.copy()\n",
    "dfmean.drop(columns=[2018,2017,2016,2015],inplace=True)\n",
    "dfmean['avg'] = dfmean.drop(59,axis=0).drop(['month','day'], axis=1).mean(axis=1)\n",
    "#previous line has lots of columns that don't need to be part of the mean\n",
    "## unnamed (second doy) brings value down alot, but it also had the daily averages in it\n",
    "# so that should have brought it back up\n",
    "\n",
    "drop_cols = ['month', 'day','doy_y2']\n",
    "dfmean['avg'] = dfmean.drop(59,axis=0).drop(drop_cols, axis=1).mean(axis=1)\n",
    "\n",
    "#make missing days after present day\n",
    "dfe[2021][dfe[2021].index > int(datetime.datetime.strftime(datetime.datetime.now(),'%j'))] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot using Altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from altair.expr import datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfe = pd.read_excel(fid,sheet_name=page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfe.drop(['month','day'],axis=1).melt('index', var_name='year', value_name='ice_conc').dropna()\n",
    "df = df[df.year!=1978]\n",
    "df['DateTime']= df.apply(lambda row: pd.datetime.strptime(str(row['year'])+' '+str(row['index']+1),'%Y %j'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestamp = df.DateTime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some basic housekeeping... \n",
    "# a limitiation of altair / javascript\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "#  Load 508 compliant NOAA colors\n",
    "OceansBlue1='#0093D0'\n",
    "OceansBlue2='#0055A4' # rebecca dark blue\n",
    "CoralRed1='#FF4438'\n",
    "SeagrassGreen1='#93D500'\n",
    "SeagrassGreen4='#D0D0D0' # This is just grey\n",
    "UrchinPurple1='#7F7FFF'\n",
    "WavesTeal1='#1ECAD3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = alt.selection_single(\n",
    "    fields=['year'], \n",
    "    empty='all',\n",
    "    bind='legend'\n",
    ")\n",
    "\n",
    "\n",
    "pastyearscolor=['#D0D0D0']*38\n",
    "pastyears= [(x) for x in range(1979,2017,1)]\n",
    "scale = alt.Scale(domain=pastyears + [2017,2018,2019,2020,2021],\n",
    "                  range=pastyearscolor+['#9acd32','#668B8B','#79CDCD','#0EBFE9', '#0055A4'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base chart setup below\n",
    "current = alt.Chart(df\n",
    ").mark_line(\n",
    "    color='grey',\n",
    "    clip=True\n",
    ").encode(\n",
    "    alt.X('monthdate(DateTime):T',title='',axis=alt.Axis(format='%b')),\n",
    "    alt.Y('ice_conc:Q',title='Ice Concentration'),\n",
    "    alt.Color('year:N',scale=scale, legend=alt.Legend(columns=4,symbolLimit=43)),\n",
    "    opacity=alt.condition(selector, alt.value(1), alt.value(0))\n",
    ").add_selection(\n",
    "    selector\n",
    ").properties(\n",
    "    width=850,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "mean = alt.Chart(df\n",
    ").mark_line(\n",
    "    color='black',\n",
    "    clip=True\n",
    ").encode(\n",
    "    alt.X('monthdate(DateTime):T'),\n",
    "    alt.Y('mean(ice_conc):Q'),\n",
    ").transform_filter(\n",
    "    alt.FieldLTEPredicate('year', 2015)\n",
    ")\n",
    "\n",
    "base_chart = (current+mean)\n",
    "\n",
    "# chart factory\n",
    "def make_chart(base_chart, region, options):\n",
    "    title = f'{region}'\n",
    "    chart = base_chart\\\n",
    "      .properties(title=title)\n",
    "    return chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {'width': 150, 'height': 150}\n",
    "allcharts = make_chart(base_chart, 'BS', options)\n",
    "\n",
    "allcharts_final = allcharts.properties(\n",
    "    background='#f4f4f4',\n",
    "    title=f\"BS Ice Extent {datestamp.strftime('%b %d %Y')}\"\n",
    ").configure(\n",
    "# fix that pesky title\n",
    "    title=alt.TitleConfig(fontSize=14, anchor='middle', offset=10),\n",
    "    legend=alt.LegendConfig(labelFontSize=12, titleFontSize=12, symbolSize=100, offset=25)\n",
    ")\n",
    "\n",
    "allcharts_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcharts_final.save('/Users/bell/Sites/shaunwbell.github.io/files/BS_IceExtent_current.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exporting of data files to csv files as long doy indexed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and for NH extent\n",
    "fid = 'ftp://sidads.colorado.edu/DATASETS/NOAA/G02135/seaice_analysis/Sea_Ice_Index_Daily_Extent_G02135_v3.0.xlsx'\n",
    "page = 'NH-Daily-Extent' #Bering-Area-km^2\n",
    "\n",
    "dfe = pd.read_excel(fid,sheet_name=page)\n",
    "dfe.reset_index(level=0, inplace=True)\n",
    "df = dfe.drop(['Unnamed: 0','Unnamed: 1','1981-2010'],axis=1).melt('index', var_name='year', value_name='ice_conc').dropna()\n",
    "df = df[df.year!=1978]\n",
    "df['DateTime']= df.apply(lambda row: pd.datetime.strptime(str(row['year'])+' '+str(row['index']+1),'%Y %j'), axis=1)\n",
    "df['index'] = df['index']+1\n",
    "df.to_csv('N_Sea_Ice_Index_Regional_Daily_Data_G02135_v3.0_doy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:altair]",
   "language": "python",
   "name": "conda-env-altair-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
