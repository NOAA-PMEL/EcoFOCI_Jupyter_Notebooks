{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Data from Home System"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## CF-6 report (daily update)\n",
    "\n",
    "Process pull data from individual databases...\n",
    "\n",
    "Generate new erddap with (for met station):\n",
    "- Daily High/Low/Average Temp\n",
    "- Daily Average Wetbulb/DewpointTemp\n",
    "- HDD/CDD (how to calculate)\n",
    "- average SLP\n",
    "- total rainfall\n",
    "- windfall average speed/average direction ... max speed (direction at time of max)\n",
    "- time of each event (on display)\n",
    "\n",
    "+ monthly max temp, min temp (average of all columns) except precip... cumulative\n",
    "+ days where temp exceeds threshold (hot and cold)\n",
    "+ days with rainfall bins\n",
    "\n",
    "- output monthly summaries as `{year}_{month}.txt` daily\n",
    "- generate annual report\n",
    "\n",
    "Generate new erddap with daily for houshold stations (combine, so maintain a location identifier)\n",
    "- Daily High/Low/Average temp\n",
    "- Daily High/Low/Average dewpoint\n",
    "- Daily High/Low/Average SLP\n",
    "\n",
    "- Monthly High/Low/Average\n",
    "\n",
    "Will want to compile all time records (with dates) for each location...\n",
    "- Alltime max/min temp\n",
    "- Alltime max/min dewpoint\n",
    "- Alltime max/min SLP\n",
    "\n",
    "- fun things to do later...\n",
    "    - consecutive days of rain\n",
    "    - consecutive days w/o rain\n",
    "    - largest daily change\n",
    "    \n",
    "- Code frequency and data ingestion\n",
    "    - daily run should pull in whole month (repeates process but simplifies output) - output to csv for \"erddap records and concat\"\n",
    "    - anual run is will use daily data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from erddapy import ERDDAP\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# for secondary/derived parameters\n",
    "from metpy.units import units\n",
    "import metpy.calc as mpcalc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_url = 'http://raspberrypi.local:8080/erddap'\n",
    "#server_url = 'http://192.168.2.3:8080/erddap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ERDDAP(server=server_url)\n",
    "df = pd.read_csv(e.get_search_url(response='csv', search_for='MoonFlower'))\n",
    "print(df['Dataset ID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id='tempest_moonflower_wx'\n",
    "\n",
    "try:\n",
    "    d = ERDDAP(server=server_url,\n",
    "        protocol='tabledap',\n",
    "        response='csv'\n",
    "    )\n",
    "    d.dataset_id=dataset_id\n",
    "except HTTPError:\n",
    "    print('Failed to generate url {}'.format(dataset_id))\n",
    "\n",
    "try:\n",
    "    df_m = d.to_pandas(\n",
    "                index_col='time (UTC)',\n",
    "                parse_dates=True,\n",
    "                skiprows=(1,)  # units information can be dropped.\n",
    "                )\n",
    "    df_m.sort_index(inplace=True)\n",
    "    df_m.columns = [x[1].split()[0] for x in enumerate(df_m.columns)]\n",
    "\n",
    "except:\n",
    "    print(f\"something failed in data download {dataset_id}\")\n",
    "    pass\n",
    "\n",
    "df_m.drop(columns=['device_id', 'bucket_step_minutes', 'wind_lull','wind_interval'],inplace=True)\n",
    "#stats are all utc driven - but we really want local daily values\n",
    "df_m=df_m.tz_convert('US/Pacific')\n",
    "\n",
    "# calculations of various parameters... metpy?\n",
    "# HDD/CDD, dewpointTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m['dewpointTemp']=mpcalc.dewpoint_from_relative_humidity(df_m.temperature.values * units.degC,\n",
    "                                                            df_m.humidity.values * units.percent)\n",
    "#wetbulb from metpy had issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m['SLP']=df_m.pressure.values * (1+((1013.25/df_m.pressure.values)**((287.05*0.0065)/9.80665)) * (0.0065*87.3)/288.15)**(9.80665/(287.05*0.0065))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_max = df_m.resample('D').max()\n",
    "df_daily_min = df_m.resample('D').min()\n",
    "df_daily_ave = df_m.resample('D').mean()\n",
    "df_daily_total = df_m.resample('1T').mean().resample('D').sum()\n",
    "df_m.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_current_month = True\n",
    "\n",
    "if use_current_month:\n",
    "    current_month = datetime.datetime.now().month\n",
    "else:\n",
    "    current_month = 7\n",
    "\n",
    "current_month_grid_data=pd.DataFrame()\n",
    "current_month_grid_data = df_daily_max[df_daily_max.index.month==current_month].temperature\n",
    "current_month_grid_data = pd.concat([current_month_grid_data,\n",
    "                                     df_daily_min[df_daily_min.index.month==current_month].temperature.round(1),\n",
    "                                     df_daily_ave[df_daily_ave.index.month==current_month].temperature.round(1),\n",
    "                                     df_daily_ave[df_daily_ave.index.month==current_month].dewpointTemp.round(1),\n",
    "                                     df_daily_ave[df_daily_ave.index.month==current_month].SLP.round(1),\n",
    "                                     df_daily_total[df_daily_total.index.month==current_month].solar_radiation.round(0),\n",
    "                                     df_daily_max[df_daily_max.index.month==current_month].uv.round(1),\n",
    "                                     df_daily_ave[df_daily_ave.index.month==current_month].wind_avg.round(1),\n",
    "                                     df_daily_ave[df_daily_ave.index.month==current_month].wind_dir.astype(int),\n",
    "                                     df_daily_max[df_daily_max.index.month==current_month].wind_gust.round(1)\n",
    "                                    ],axis=1)\n",
    "current_month_grid_data.columns=('max_temperature','min_temperature','mean_temperature','mean_dewpoint','mean SLP','total_solar_radiation','max_uv_index','average speed','average dir','max gust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_month_grid_data['station_id'] = 'tempest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should go to erddap\n",
    "current_month_grid_data.to_csv(f'Data/MoonflowerTempest_2020{str(current_month).zfill(2)}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['color: red' if v else '' for v in is_max]\n",
    "\n",
    "def highlight_min(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_min = s == s.min()\n",
    "    return ['color: blue' if v else '' for v in is_min]\n",
    "\n",
    "current_month_grid_data.drop('station_id',axis=1).style.apply(highlight_max).apply(highlight_min).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### need to manage daily records, monthly records, alltime records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repeat for each sensor on property\n",
    "\n",
    "choose month or use current (starting with data subsetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_current_month:\n",
    "    constraints = {\n",
    "        'time>=': datetime.datetime.now().strftime('%Y-%m-01T00:00:00Z'),\n",
    "    }\n",
    "else:\n",
    "    constraints = {\n",
    "        'time>=': '2020-01-01T00:00:00Z',\n",
    "        'time<=': '2027-02-10T00:00:00Z',\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldatasets=['channel_1027974_thingspeak',\n",
    "            'channel_1037066_thingspeak',\n",
    "            'channel_1047747_thingspeak',\n",
    "            'channel_843357_thingspeak',\n",
    "            'channel_rpi']\n",
    "df_all = {}\n",
    "\n",
    "for dataset_id in alldatasets:\n",
    "    try:\n",
    "        d = ERDDAP(server=server_url,\n",
    "            protocol='tabledap',\n",
    "            response='csv'\n",
    "        )\n",
    "        d.dataset_id=dataset_id\n",
    "        d.constraints=constraints\n",
    "        \n",
    "    except HTTPError:\n",
    "        print('Failed to generate url {}'.format(dataset_id))\n",
    "\n",
    "    try:\n",
    "        df_m = d.to_pandas(\n",
    "                    index_col='time (UTC)',\n",
    "                    parse_dates=True,\n",
    "                    skiprows=(1,)  # units information can be dropped.\n",
    "                    )\n",
    "        df_m.sort_index(inplace=True)\n",
    "        df_m.columns = [x[1].split()[0] for x in enumerate(df_m.columns)]\n",
    "\n",
    "    except:\n",
    "        print(f\"something failed in data download {dataset_id}\")\n",
    "        pass\n",
    "\n",
    "    #stats are all utc driven - but we really want local daily values\n",
    "    df_m=df_m.tz_convert('US/Pacific')\n",
    "    df_all.update({dataset_id:df_m})\n",
    "    # calculations of various parameters... metpy?\n",
    "    # HDD/CDD, dewpointTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in enumerate(df_all):\n",
    "    print(df_all[v].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_current_month:\n",
    "    current_month = datetime.datetime.now().month\n",
    "else:\n",
    "    current_month = 7\n",
    "    \n",
    "for k,v in enumerate(df_all):\n",
    "    print(df_all[v].keys())\n",
    "    df_daily_max = df_all[v].resample('D').max()\n",
    "    df_daily_min = df_all[v].resample('D').min()\n",
    "    df_daily_ave = df_all[v].resample('D').mean()\n",
    "    if ('RH_Percent' in df_all[v].keys()) and ('temperature' in df_all[v].keys()) and (not 'Barotemperature' in df_all[v].keys()):\n",
    "        print(f\"processing {v} :0\")\n",
    "        current_month_grid_data=pd.DataFrame()\n",
    "        current_month_grid_data = df_daily_max[df_daily_max.index.month==current_month].temperature\n",
    "        current_month_grid_data = pd.concat([current_month_grid_data,\n",
    "                                             df_daily_min[df_daily_min.index.month==current_month].temperature.round(1),\n",
    "                                             df_daily_ave[df_daily_ave.index.month==current_month].temperature.round(1),\n",
    "                                             df_daily_ave[df_daily_ave.index.month==current_month].RH_Percent.round(1),\n",
    "                                            ],axis=1)\n",
    "        current_month_grid_data.columns=('max_temperature','min_temperature','mean_temperature','mean_humidity')\n",
    "        current_month_grid_data['station_id'] = v    \n",
    "        current_month_grid_data.to_csv(f'Data/{v}_2020{str(current_month).zfill(2)}.csv')\n",
    "    elif (not 'RH_Percent' in df_all[v].keys()) and ('temperature' in df_all[v].keys()) and (not 'Barotemperature' in df_all[v].keys()):\n",
    "        print(f\"processing {v} :1\")\n",
    "        current_month_grid_data=pd.DataFrame()\n",
    "        current_month_grid_data = df_daily_max[df_daily_max.index.month==current_month].temperature\n",
    "        current_month_grid_data = pd.concat([current_month_grid_data,\n",
    "                                             df_daily_min[df_daily_min.index.month==current_month].temperature.round(1),\n",
    "                                             df_daily_ave[df_daily_ave.index.month==current_month].temperature.round(1),\n",
    "                                            ],axis=1)\n",
    "        current_month_grid_data.columns=('max_temperature','min_temperature','mean_temperature')\n",
    "        current_month_grid_data['station_id'] = v\n",
    "        \n",
    "        #this should go to erddap\n",
    "        current_month_grid_data.to_csv(f'Data/{v}_2020{str(current_month).zfill(2)}.csv')\n",
    "    elif ('RH_Percent' in df_all[v].keys()) and ('temperature' in df_all[v].keys()) and ('Barotemperature' in df_all[v].keys()):\n",
    "        print(f\"processing {v} :2\")\n",
    "        current_month_grid_data=pd.DataFrame()\n",
    "        current_month_grid_data = df_daily_max[df_daily_max.index.month==current_month].Barotemperature\n",
    "        current_month_grid_data = pd.concat([current_month_grid_data,\n",
    "                                             df_daily_min[df_daily_min.index.month==current_month].Barotemperature.round(1),\n",
    "                                             df_daily_ave[df_daily_ave.index.month==current_month].Barotemperature.round(1),\n",
    "                                            ],axis=1)\n",
    "        current_month_grid_data.columns=('max_temperature','min_temperature','mean_temperature')\n",
    "        current_month_grid_data['station_id'] = v\n",
    "        \n",
    "        #this should go to erddap\n",
    "        current_month_grid_data.to_csv(f'Data/{v}_2020{str(current_month).zfill(2)}.csv')\n",
    "    else:\n",
    "        print(f\"passing {v} :3\")\n",
    "        pass\n",
    "    \n",
    "    print(f'{v}')\n",
    "current_month_grid_data.drop('station_id',axis=1).style.apply(highlight_max).apply(highlight_min).format(\"{:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
