{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glider UP/Down Merge (to eliminate thermocline spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__pyversion__==3.7   \n",
    "__author__==S.Bell\n",
    "\n",
    "Updated routine for evaluating glider data to compensate for salinity spikes at sharp interfaces.\n",
    "Original code was developed with 2017 deployment in mind.  This code will work for 2017 and 2019+ (which evolved to have varying sample frequency's recorded by each instrument instead of all data on matching time intervals).\n",
    "\n",
    "Data is ingested and read from an ERDDAP server run internally.  It is then saved for future erddap distribution.\n",
    "\n",
    "Data to keep.  Merged profiles have T/S (see furthur description)/oxy/sigmat/chlor maintained.  bin to 1m. If up and down are both ok then only keep upcast\n",
    "\n",
    " Purpose:\n",
    " --------\n",
    " Subset Oculus Glider Data from downcast/upcast dives to singel location cast profiles.\n",
    "\n",
    " The cast profiles may be created with one of the following three assumptions:\n",
    "    - downcast only, gridded to 1m bins, geolocation as last good surface point or linear\n",
    "        interpolation if no surface point\n",
    "    - upcast only, gridded to 1m bins, geolocation of first good surface point or linear \n",
    "        interpolation if no surface point ***keep***\n",
    "    - hybrid, gridded to 1m bins, geolocation of last good surface point or linear interpolation \n",
    "        if no surface point.  **This is used to address salinity spikes in sharp interfaces**\n",
    "\n",
    "\n",
    " Assumptions:\n",
    " ------------\n",
    " dt/dz threshold on both up and donwcast set to *** 1 degC/m ***\n",
    "\n",
    " on merged profiles - keep: Temp, Salinity, Flourometry, PAR (u,d), (oxy?), lat, lon, depth/press\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#System Stack\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "#Science Stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xa\n",
    "import seawater as sw\n",
    "\n",
    "from erddapy import ERDDAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### these routines assume xarray ingestion of netcdf files... either from orig files or erddap\n",
    "\n",
    "def find_sharp_grad(xdf,thresh=-1.0):\n",
    "    ### find thresholds in cast\n",
    "    # lower bound to downcast\n",
    "    # bottom of profile\n",
    "    # upper bound of upcast\n",
    "\n",
    "    dtdz_down_thresh = thresh\n",
    "    dtdz_up_thresh = thresh\n",
    "    dtdz = np.gradient(xdf.temperature,xdf.depth)\n",
    "\n",
    "    ### Assuming a two layer system with a sharp interface \n",
    "    #    Find the bottom of the upper layer on the downcast\n",
    "    #    Find the top of the bottom layer on the upcast\n",
    "    # fail out of this try statement if none of the sharpness criterion are met\n",
    "    upper_depth = xdf.depth[dtdz<dtdz_down_thresh][0]\n",
    "    upper_depth_index = np.where(xdf.depth == upper_depth)[0] - 1 #make shallower by one\n",
    "    if len(upper_depth_index) >1 :\n",
    "        upper_depth_index = np.array([upper_depth_index[0]])\n",
    "    bottom_depth = xdf.depth.max()\n",
    "    bottom_depth_index = np.where(xdf.depth == bottom_depth)[0]\n",
    "    lower_depth = xdf.depth[bottom_depth_index[0]:][dtdz[bottom_depth_index[0]:]<dtdz_up_thresh][0]\n",
    "    lower_depth_index = np.where(xdf.depth == lower_depth)[0] - 1 #make deeper by one\n",
    "            \n",
    "    return (upper_depth,upper_depth_index,bottom_depth,bottom_depth_index,lower_depth,lower_depth_index)\n",
    "\n",
    "\n",
    "def bin_ave(thinned_xarray_set,depth_bin,depth_bin_labels):\n",
    "    df = xdfa.to_dataframe()\n",
    "    bins=pd.cut(df.index, depth_bin, labels=depth_bin_labels)\n",
    "    dfg = df.groupby(bins).mean()\n",
    "        \n",
    "    return dfg\n",
    "\n",
    "def find_max_inversion(temperature=None,salinity=None,pressure=None):\n",
    "    sigmat = sw.dens(s=salinity,t=temperature,p=pressure) - 1000.\n",
    "    dtdz = np.gradient(sigmat,pressure)\n",
    "\n",
    "    return np.nanmin(dtdz),np.nanargmin(dtdz)\n",
    "\n",
    "### Fill Profile\n",
    "# Scale both temperature and salinty to 0->1\n",
    "# this maps the shape of the temperature profile to the salinity profile\n",
    "def scale(x):\n",
    "    return (x-min(x)) / (max(x) - min(x))\n",
    "\n",
    "def rescale(x,y):\n",
    "    return (1-x)*(y[1] - y[0]) + y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access dataset and get profileid's to loop through\n",
    "server_url = 'http://downdraft.pmel.noaa.gov:8080/erddap'\n",
    "\n",
    "d = ERDDAP(server=server_url,\n",
    "           protocol='tabledap',\n",
    "           response='csv',\n",
    "          )\n",
    "\n",
    "d.dataset_id='sg401_2017'\n",
    "\n",
    "d.variables =  [\n",
    " 'profileid',\n",
    "]\n",
    "\n",
    "df = d.to_pandas(\n",
    "    skiprows=(1,)  # units information can be dropped.\n",
    ").dropna()\n",
    "\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get profile and perform analysis\n",
    "d = ERDDAP(server=server_url,\n",
    "           protocol='tabledap',\n",
    "           response='nc',\n",
    "          )\n",
    "\n",
    "d.dataset_id='sg401_2017'\n",
    "d.response = 'nc'\n",
    "d.variables =  [\n",
    "    \"profileid\",\n",
    "    \"time\",\n",
    "    \"salinity\",\n",
    "    \"temperature\",\n",
    "    \"pressure\",\n",
    "    \"wlbb2fl_sig695nm_adjusted\",\n",
    "    \"depth\",\n",
    "]\n",
    "#download every profile individually or all at once?\n",
    "#downloading all then analyzing is more efficient data transmission wise as these files are actually small\n",
    "#may not be as easy when multiple data sets need to be combined.. maybe easier to go profile by profile\n",
    "#d.constraints = { 'profileid=':'p4010005'}\n",
    "\n",
    "ds = d.to_xarray(decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/numpy/lib/function_base.py:1067: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  a = -(dx2)/(dx1 * (dx1 + dx2))\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/numpy/lib/function_base.py:1069: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c = dx1 / (dx2 * (dx1 + dx2))\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/numpy/lib/function_base.py:1075: RuntimeWarning: invalid value encountered in add\n",
      "  out[tuple(slice1)] = a * f[tuple(slice2)] + b * f[tuple(slice3)] + c * f[tuple(slice4)]\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in less\n",
      "/Users/bell/anaconda2/envs/py37/lib/python3.7/site-packages/ipykernel_launcher.py:23: RuntimeWarning: invalid value encountered in less\n"
     ]
    }
   ],
   "source": [
    "for i,k in df.iloc[1:10].iterrows():\n",
    "    \n",
    "    try:\n",
    "        (upper_depth,upper_depth_index,bottom_depth,bottom_depth_index,lower_depth,lower_depth_index) = find_sharp_grad( ds.where(ds.profileid == k.profileid) )\n",
    "    except:\n",
    "        print(\"not gonna work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
